<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>

<script type="text/javascript" charset="utf-8" src="https://ajax.googleapis.com/ajax/libs/jquery/1.3.2/jquery.min.js"></script>
<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

<style type="text/css">
body {
    font-family: "Titillium Web", "HelveticaNeue-Light", "Helvetica Neue Light", "Helvetica Neue", Helvetica, Arial, "Lucida Grande", sans-serif;
    font-weight: 300;
    font-size: 17px;
    margin-left: auto;
    margin-right: auto;
}

@media screen and (min-width: 980px){
    body {
        width: 980px;
    }
}

h1 {
    font-weight:300;
    line-height: 1.15em;
}

h2 {
    font-size: 1.75em;
}
a:link,a:visited {
    color: #0E710E;
    text-decoration: none;
}
a:hover {
    color: #208799;
}
h1 {
    text-align: center;
}
h2,h3 {
    text-align: left;
}

h1 {
    font-size: 40px;
    font-weight: 500;
}
h2 {
    font-weight: 400;
    margin: 16px 0px 4px 0px;
}
h3 {
    font-weight: 600;
    margin: 16px 0px 4px 0px;
}

.paper-title {
    padding: 1px 0px 1px 0px;
}
section {
    margin: 32px 0px 32px 0px;
    text-align: justify;
    clear: both;
}
.col-5 {
     width: 20%;
     float: left;
}
.col-4 {
     width: 25%;
     float: left;
}
.col-3 {
     width: 33%;
     float: left;
}
.col-2 {
     width: 50%;
     float: left;
}
.col-1 {
     width: 100%;
     float: left;
}

.author-row, .affil-row {
    font-size: 26px;
}

.author-row-new {
    text-align: center;
}

.author-row-new a {
    display: inline-block;
    font-size: 20px;
    padding: 4px;
}

.author-row-new sup {
    color: #313436;
    font-size: 12px;
}

.affiliations-new {
    font-size: 18px;
    text-align: center;
    width: 80%;
    margin: 0 auto;
    margin-bottom: 20px;
}

.row {
    margin: 16px 0px 16px 0px;
}
.authors {
    font-size: 26px;
}
.affiliatons {
    font-size: 18px;
}
.affil-row {
    margin-top: 18px;
}
.teaser {
    max-width: 100%;
}
.text-center {
    text-align: center;  
}
.screenshot {
    width: 256px;
    border: 1px solid #ddd;
}
.screenshot-el {
    margin-bottom: 16px;
}
hr {
    height: 1px;
    border: 0;
    border-top: 1px solid #ddd;
    margin: 0;
}
.material-icons {
    vertical-align: -6px;
}
p {
    line-height: 1.25em;
}
.caption {
    font-size: 16px;
    color: #666;
    margin-top: 4px;
    margin-bottom: 10px;
}
video {
    display: block;
    margin: auto;
}
figure {
    display: block;
    margin: auto;
    margin-top: 10px;
    margin-bottom: 10px;
}
#bibtex pre {
    font-size: 14px;
    background-color: #eee;
    padding: 16px;
}
.blue {
    color: #0E710E;
    font-weight: bold;
}
.orange {
    color: #d35400;
    font-weight: bold;
}
.flex-row {
    display: flex;
    flex-flow: row wrap;
    padding: 0;
    margin: 0;
    list-style: none;
}

.paper-btn-coming-soon {
    position: relative;
    top: 0;
    left: 0;
}

.coming-soon {
    position: absolute;
    top: -15px;
    right: -15px;
}

.paper-btn {
  position: relative;
  text-align: center;
  display: inline-block;
  margin: 8px;
  padding: 10px 16px;
  border-width: 0;
  outline: none;
  border-radius: 10px;
  background-color: #FF6F61;
  color: white !important;
  font-size: 18px;
  width: 120px;
  font-weight: 600;
  transition: background-color 0.3s ease, transform 0.3s ease;
}

.paper-btn:hover {
    background-color: #FF8563;
    transform: translateY(-2px);
}

.paper-btn-parent {
    display: flex;
    justify-content: center;
    margin: 16px 0px;
}

.github-btn {
    position: relative;
    text-align: center;
    display: inline-block;
    margin: 8px;
    padding: 10px 16px;
    border-width: 0;
    outline: none;
    border-radius: 10px;
    background-color: #24292e;
    color: white !important;
    font-size: 18px;
    width: 120px;
    font-weight: 600;
    transition: background-color 0.3s ease, transform 0.3s ease;
}

.github-btn:hover {
    background-color: #4f5358;
    transform: translateY(-2px;
}

.container {
    margin-left: auto;
    margin-right: auto;
    padding-left: 16px;
    padding-right: 16px;
}

.venue {
    font-size: 23px;
}

.topnav {
    background-color: #EEEEEE;
    overflow: hidden;
}

.topnav div {
    max-width: 1070px;
    margin: 0 auto;
}

.topnav a {
    display: inline-block;
    color: black;
    text-align: center;
    vertical-align: middle;
    padding: 16px 16px;
    text-decoration: none;
    font-size: 18px;
}

.topnav img {
    padding: 2px 0px;
    width: 100%;
    margin: 0.2em 0px 0.3em 0px;
    vertical-align: middle;
}

pre {
    font-size: 0.9em;
    padding-left: 7px;
    padding-right: 7px;
    padding-top: 3px;
    padding-bottom: 3px;
    border-radius: 3px;
    background-color: rgb(235, 235, 235);
    overflow-x: auto;
}

.download-thumb {
    display: flex;
}

@media only screen and (max-width: 620px) {
    .download-thumb {
        display: none;
    }
}

.paper-stuff {
    width: 50%;
    font-size: 20px;
}

@media only screen and (max-width: 620px) {
    .paper-stuff {
        width: 100%;
    }
}
* {
  box-sizing: border-box;
}

.column {
  text-align: center;
  float: left;
  width: 16.666%;
  padding: 5px;
}
.column3 {
  text-align: center;
  float: left;
  width: 33.333%;
  padding: 5px;
}
.border-right {
    border-right: 1px solid black;
}
.border-bottom{
    border-bottom: 1px solid black;
}

/* Clearfix (clear floats) */
.row::after {
  content: "";
  clear: both;
  display: table;
}

/* Responsive layout - makes the three columns stack on top of each other instead of next to each other */
@media screen and (max-width: 500px) {
  .column {
    width: 100%;
  }
}
@media screen and (max-width: 500px) {
  .column3 {
    width: 100%;
  }
}

</style>

<script type="text/javascript" src="../js/hidebib.js"></script>
    <link href='https://fonts.googleapis.com/css?family=Titillium+Web:400,600,400italic,600italic,300,300italic' rel='stylesheet' type='text/css'>
    <head>
        <title>Representation Alignment for Generation: Training Diffusion Transformers Is Easier Than You Think </title>
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta property="og:description" content="Representation Alignment for Generation: Training Diffusion Transformers Is Easier Than You Think"/>
        <link rel="stylesheet" href="https://fonts.googleapis.com/icon?family=Material+Icons">
        <link href="https://fonts.googleapis.com/css2?family=FontAwesome" rel="stylesheet">
        <meta name="twitter:card" content="summary_large_image">
        <meta name="twitter:creator" content="@sihyun_yu">
        <meta name="twitter:title" content="Representation Alignment for Generation: Training Diffusion Transformers Is Easier Than You Think">
    </head>

 <body>
<div class="container">
    <div class="paper-title">
    <h1>
        <font color="#0E710E">Rep</font>resentation </font><font color="#0E710E">A</font>lignment for Generation:
        Training Diffusion Transformers Is Easier Than You Think
    </h1>
    </div>

    <div id="authors">
        <center>
            <div class="author-row-new">
                <a href="https://sihyun.me">Sihyun Yu<sup>1</sup></a>,
                <a href="https://www.linkedin.com/in/SangkyungKwak/">Sangkyung Kwak<sup>1</sup></a>,
                <a href="https://huiwon-jang.github.io/">Huiwon Jang<sup>1</sup></a>,
                <a href="https://jh-jeong.github.io/">Jongheon Jeong<sup>2</sup></a>,
                <a href="http://jonathan-huang.org/">Jonathan Huang<sup>3</sup></a>,
              <a href="https://alinlab.kaist.ac.kr/shin.html">Jinwoo Shin<sup>1</sup></a>,
                <a href="https://www.sainingxie.com/">Saining Xie<sup>4</sup></a>
            </div>
        </center>
        <center>
        <div class="affiliations">
            <span><sup>1</sup>KAIST</span>&nbsp;&nbsp;&nbsp;
            <span><sup>2</sup>Korea University</span>&nbsp;&nbsp;&nbsp;
            <span><sup>3</sup>Scaled Foundations</span>&nbsp;&nbsp;&nbsp;
            <span><sup>4</sup>New York University</span> <br/>
        </div>
        <div class="affil-row">
            <div class="venue text-center"><b>Preprint</b></div>
        </div>

        </center>

        <div style="clear: both">
            <div class="paper-btn-parent">
                <a class="paper-btn" href="https://arxiv.org/abs/2403.14148">
                    <span class="fa fa-file-text-o"></span>
                     Paper
                </a>
                <a class="github-btn" href="https://github.com/sihyun-yu/CMD">
                    <span class="fa fa-github"></span>
                     Code
                </a>
            </div>
        </div>
    </div>

    <section id="news">
        <hr>
        <h2>News</h2>
        <div class="row">
            <div><span class="material-icons"> event </span> [Oct 2024] Our project page is released.</div>
        </div>
    </section>

    <section id="abstract"/>
        <hr>
        <h2>Abstract</h2>
        <div class="flex-row">
            <p>
            Recent studies have shown that the denoising process in (generative) diffusion models can induce meaningful (discriminative) representations inside the model,
            though the quality of these representations still lags behind those learned through recent self-supervised learning methods. We argue that one main bottleneck
            in training large-scale diffusion models for generation comes down to learning these good representations, and training can become significantly easier
            when the model is aided by strong external visual representations. We study this by introducing a straightforward regularization called
            REPresentation Alignment (REPA), which aligns the projections of noisy input hidden states in denoising networks with clean image representations
            obtained from external, pretrained visual encoders. The results are striking: our simple strategy yields significant improvements in both training efficiency
            and generation quality when applied to popular diffusion and flow-based transformers, such as DiTs and SiTs.
            For instance, our method can speed up SiT training by over 17.5x, matching the performance (without classifier-free guidance) of a SiT-XL model trained
            for 7M steps in less than 400K steps. Additionally, in terms of final generation quality,
            our approach achieves a superior FID score of 1.80 when using guidance and 1.42 with guidance interval.
            </p>
        </div>
    </section>

</div>
</body>
</html>